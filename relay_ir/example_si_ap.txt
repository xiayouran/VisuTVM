fn (%input0: Tensor[(1, 3, 32, 32), float32] /* ty=Tensor[(1, 3, 32, 32), float32] */, %conv1.weight: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */, %bn.weight: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %bn.bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %bn.running_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %bn.running_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %linear.weight: Tensor[(10, 1600), float32] /* ty=Tensor[(10, 1600), float32] */, %linear.bias: Tensor[(10), float32] /* ty=Tensor[(10), float32] */) -> Tensor[(10), float32] {
  %0 = add(%bn.running_var, 1e-05f /* ty=float32 */) /* ty=Tensor[(64), float32] */;
  %1 = sqrt(%0) /* ty=Tensor[(64), float32] */;
  %2 = divide(1f /* ty=float32 */, %1) /* ty=Tensor[(64), float32] */;
  %3 = multiply(%2, %bn.weight) /* ty=Tensor[(64), float32] */;
  %4 = nn.conv2d(%input0, %conv1.weight, strides=[3, 3], padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 10, 10), float32] */;
  %5 = expand_dims(%3, axis=1, num_newaxis=2) /* ty=Tensor[(64, 1, 1), float32] */;
  %6 = negative(%bn.running_mean) /* ty=Tensor[(64), float32] */;
  %7 = multiply(%6, %3) /* ty=Tensor[(64), float32] */;
  %8 = add(%7, %bn.bias) /* ty=Tensor[(64), float32] */;
  %9 = multiply(%4, %5) /* ty=Tensor[(1, 64, 10, 10), float32] */;
  %10 = expand_dims(%8, axis=1, num_newaxis=2) /* ty=Tensor[(64, 1, 1), float32] */;
  %11 = add(%9, %10) /* ty=Tensor[(1, 64, 10, 10), float32] */;
  %12 = nn.relu(%11) /* ty=Tensor[(1, 64, 10, 10), float32] */;
  %13 = nn.avg_pool2d(%12, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0], count_include_pad=True) /* ty=Tensor[(1, 64, 5, 5), float32] */;
  %14 = reshape(%13, newshape=[-1, 1, 1, 1]) /* ty=Tensor[(1600, 1, 1, 1), float32] */;
  %15 = squeeze(%14, axis=[1, 2, 3]) /* ty=Tensor[(1600), float32] */;
  %16 = expand_dims(%15, axis=0) /* ty=Tensor[(1, 1600), float32] */;
  %17 = transpose(%linear.weight, axes=[1, 0]) /* ty=Tensor[(1600, 10), float32] */;
  %18 = nn.matmul(%16, %17, units=None) /* ty=Tensor[(1, 10), float32] */;
  %19 = squeeze(%18, axis=[0]) /* ty=Tensor[(10), float32] */;
  %20 = add(%19, %linear.bias) /* ty=Tensor[(10), float32] */;
  nn.softmax(%20, axis=0) /* ty=Tensor[(10), float32] */
} /* ty=fn (Tensor[(1, 3, 32, 32), float32], Tensor[(64, 3, 3, 3), float32], Tensor[(64), float32], Tensor[(64), float32], Tensor[(64), float32], Tensor[(64), float32], Tensor[(10, 1600), float32], Tensor[(10), float32]) -> Tensor[(10), float32] */