fn (%x: Tensor[(2, 4, 10, 3), float32] /* ty=Tensor[(2, 4, 10, 3), float32] */, %weight: Tensor[(3, 3, 1, 3), float32] /* ty=Tensor[(3, 3, 1, 3), float32] */, %in_bias: Tensor[(3), float32] /* ty=Tensor[(3), float32] */) -> Tensor[(2, 4, 10, 3), float32] {
  %0 = nn.relu(%x) /* ty=Tensor[(2, 4, 10, 3), float32] */;
  %1 = divide(%in_bias, meta[relay.Constant][0] /* ty=Tensor[(3), float32] */) /* ty=Tensor[(3), float32] */;
  %2 = subtract(%0, %1) /* ty=Tensor[(2, 4, 10, 3), float32] */;
  %3 = multiply(%weight, meta[relay.Constant][0] /* ty=Tensor[(3), float32] */) /* ty=Tensor[(3, 3, 1, 3), float32] */;
  %4 = multiply(%weight, meta[relay.Constant][0] /* ty=Tensor[(3), float32] */) /* ty=Tensor[(3, 3, 1, 3), float32] */;
  %5 = nn.conv2d(%2, %3, padding=[1, 1, 1, 1], groups=3, channels=3, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* ty=Tensor[(2, 4, 10, 3), float32] */;
  %6 = nn.conv2d(%2, %4, padding=[1, 1, 1, 1], groups=3, channels=3, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* ty=Tensor[(2, 4, 10, 3), float32] */;
  add(%5, %6) /* ty=Tensor[(2, 4, 10, 3), float32] */
} /* ty=fn (Tensor[(2, 4, 10, 3), float32], Tensor[(3, 3, 1, 3), float32], Tensor[(3), float32]) -> Tensor[(2, 4, 10, 3), float32] */
